<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>分类: spark - iBuddha</title><meta description="iBuddha的blog"><meta property="og:type" content="blog"><meta property="og:title" content="iBuddha"><meta property="og:url" content="https://ibuddha.github.io/"><meta property="og:site_name" content="iBuddha"><meta property="og:description" content="iBuddha的blog"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://ibuddha.github.io/img/og_image.png"><meta property="article:author" content="xing"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ibuddha.github.io"},"headline":"iBuddha","image":["https://ibuddha.github.io/img/og_image.png"],"author":{"@type":"Person","name":"xing"},"description":"iBuddha的blog"}</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/lotus.png" alt="iBuddha" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">分类</a></li><li class="is-active"><a href="#" aria-current="page">spark</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-16T13:45:54.000Z" title="2020-08-16T13:45:54.000Z">2020-08-16</time><span class="level-item"> xing </span><span class="level-item"><a class="link-muted" href="/categories/spark/">spark</a></span><span class="level-item">13 分钟 读完 (大约 1879 个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/16/pushdown/">spark里的filter和projection pushdown</a></h1><div class="content"><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>predicate pushdown也叫filter pushdown。</p>
<p>所以，有两种pushdown。</p>
<ul>
<li>projection pushdown， 用于<code>select</code> 的pushdown</li>
<li>filter pushdown, 用于<code>filter</code>的pushdown</li>
</ul>
<p>先来明确一下这俩在干嘛。</p>
<h2 id="1-1-projection-pushdown"><a href="#1-1-projection-pushdown" class="headerlink" title="1.1 projection pushdown"></a>1.1 projection pushdown</h2><blockquote>
<p>Projection Pushdown minimizes data transfer between MapR Database and the Apache Spark engine by omitting unnecessary fields from table scans. It is especially beneficial when a table contains many columns.</p>
</blockquote>
<p>projection pushdown通过在table scan过程中忽略不需要的列来减少从数据源读取的数据量。把projection下堆到数据源处。</p>
<p>当使用<code>select</code>的时候，会进行projection pushdown，比如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">            </span><br><span class="line">df = spark_session.loadFromMapRDB(<span class="string">"/tmp/user_profiles"</span>)</span><br><span class="line">df.select(<span class="string">"_id"</span>, <span class="string">"first_name"</span>, <span class="string">"last_name"</span>)</span><br></pre></td></tr></table></figure>

<h2 id="1-2-filter-pushdown"><a href="#1-2-filter-pushdown" class="headerlink" title="1.2 filter pushdown"></a>1.2 filter pushdown</h2><p>把筛选行的filter下推到数据源处。</p>
<p>也是会减少从数据源传输到spark engine的数据量，但减少的单位是“行”，而projection pushdown减少的单位是“列”。</p>
<p>比如</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">            </span><br><span class="line">df = spark_session.loadFromMapRDB(<span class="string">"/tmp/user_profiles"</span>)</span><br><span class="line">df.filter(<span class="string">"first_name = 'Bill'"</span>)</span><br></pre></td></tr></table></figure>

<p>支持以下filter的pushdown:</p>
<ul>
<li><code>=</code> 和<code>!=</code></li>
<li><code>&lt;</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;=</code></li>
<li><code>IN</code></li>
<li><code>LIKE</code></li>
<li><code>AND</code>， <code>OR</code></li>
<li><code>NOT</code></li>
</ul>
<h2 id="1-3-限制"><a href="#1-3-限制" class="headerlink" title="1.3 限制"></a>1.3 限制</h2><p>filter pushdown不支持复杂类型：array, map, struct, 比如</p>
<p>scala</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.filter($<span class="string">"address.city"</span> === <span class="string">"Milpitas"</span>)</span><br></pre></td></tr></table></figure>

<p>java</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.filter(col(&quot;address.city&quot;).equalTo(&quot;Milpitas&quot;));</span><br></pre></td></tr></table></figure>



<p>projection pushdown也不支持这些复杂类型， 比如</p>
<p>scala</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ds.select($&quot;hobbies&quot; (0))</span><br></pre></td></tr></table></figure>

<p>java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.select(col(<span class="string">"hobbies"</span>).getItem(<span class="number">0</span>));</span><br></pre></td></tr></table></figure>

<p>但是spark3.0进行了一些改进。</p>
<h1 id="2-databricks关于FilterPushdown的例子"><a href="#2-databricks关于FilterPushdown的例子" class="headerlink" title="2. databricks关于FilterPushdown的例子"></a>2. databricks关于FilterPushdown的例子</h1><p>databricks有一些例子<a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/4201913720573284/4413065072037724/latest.html">How logical plan optimizations work in Catalyst</a></p>
<h2 id="2-1-more-interesting-example"><a href="#2-1-more-interesting-example" class="headerlink" title="2.1 more interesting example"></a>2.1 more interesting example</h2><p>创建两个DataFrame</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> items = <span class="type">Seq</span>((<span class="number">0</span>, <span class="string">"Macbook Pro"</span>, <span class="number">1999.0</span>), (<span class="number">1</span>, <span class="string">"Macbook Air"</span>, <span class="number">1500.0</span>), (<span class="number">2</span>, <span class="string">"iPad Air"</span>, <span class="number">1200.0</span>)).toDF(<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"price"</span>)</span><br><span class="line"><span class="keyword">val</span> orders = <span class="type">Seq</span>((<span class="number">100</span>, <span class="number">0</span>, <span class="number">1</span>), (<span class="number">100</span>, <span class="number">1</span>, <span class="number">1</span>), (<span class="number">101</span>, <span class="number">2</span>, <span class="number">3</span>)).toDF(<span class="string">"id"</span>, <span class="string">"itemid"</span>, <span class="string">"count"</span>)</span><br><span class="line"></span><br><span class="line">items.createOrReplaceTempView(<span class="string">"item"</span>)</span><br><span class="line">orders.createOrReplaceTempView(<span class="string">"order"</span>)</span><br></pre></td></tr></table></figure>

<p>然后搞一个简单的join以及filter</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> order.id, item.name, item.price, order.count</span><br><span class="line"><span class="keyword">FROM</span> item</span><br><span class="line"><span class="keyword">JOIN</span> <span class="keyword">order</span> </span><br><span class="line"><span class="keyword">WHERE</span> item.id = order.itemid <span class="keyword">and</span> item.price &lt; <span class="number">1400</span> <span class="keyword">and</span> order.count &gt; <span class="number">2</span> - <span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="2-1-1-analyzed-plan"><a href="#2-1-1-analyzed-plan" class="headerlink" title="2.1.1 analyzed plan"></a>2.1.1 analyzed plan</h3><p>然后看<strong>analyzed plan</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> analyzedPlan = sql(<span class="string">"SELECT order.id, item.name, item.price, order.count FROM item JOIN order WHERE item.id = order.itemid and item.price &lt; 1400 and order.count &gt; 2 - 1"</span>).queryExecution.analyzed</span><br></pre></td></tr></table></figure>

<p>结果为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">analyzedPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">Project [id#15942, name#15929, price#15930, count#15944]</span><br><span class="line">+- Filter (((id#15928 &#x3D; itemid#15943) &amp;&amp; (price#15930 &lt; cast(1400 as double))) &amp;&amp; (count#15944 &gt; (2 - 1)))</span><br><span class="line">   +- Join Inner</span><br><span class="line">      :- SubqueryAlias item</span><br><span class="line">      :  +- Project [_1#15924 AS id#15928, _2#15925 AS name#15929, _3#15926 AS price#15930]</span><br><span class="line">      :     +- LocalRelation [_1#15924, _2#15925, _3#15926]</span><br><span class="line">      +- SubqueryAlias order</span><br><span class="line">         +- Project [_1#15938 AS id#15942, _2#15939 AS itemid#15943, _3#15940 AS count#15944]</span><br><span class="line">            +- LocalRelation [_1#15938, _2#15939, _3#15940]</span><br></pre></td></tr></table></figure>

<p>这里边<code>Filter</code>是<code>Join</code>的父节点，意味着filter条件里的<code>item.price &lt; 1400 and order.count &gt; 2 - 1</code>是在join之后才被执行。</p>
<h3 id="2-1-2-optimized-plan"><a href="#2-1-2-optimized-plan" class="headerlink" title="2.1.2 optimized plan"></a>2.1.2 optimized plan</h3><p>看optimized plan</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Apply Spark SQL optimizations</span></span><br><span class="line"><span class="keyword">val</span> optimizedPlan = <span class="type">SimpleTestOptimizer</span>.execute(analyzedPlan)</span><br></pre></td></tr></table></figure>

<p>结果为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">optimizedPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">Project [id#15942, name#15929, price#15930, count#15944]</span><br><span class="line">+- Join Inner, (id#15928 &#x3D; itemid#15943)</span><br><span class="line">   :- Project [_1#15924 AS id#15928, _2#15925 AS name#15929, _3#15926 AS price#15930]</span><br><span class="line">   :  +- Filter (_3#15926 &lt; 1400.0)</span><br><span class="line">   :     +- LocalRelation [_1#15924, _2#15925, _3#15926]</span><br><span class="line">   +- Project [_1#15938 AS id#15942, _2#15939 AS itemid#15943, _3#15940 AS count#15944]</span><br><span class="line">      +- Filter (_3#15940 &gt; 1)</span><br><span class="line">         +- LocalRelation [_1#15938, _2#15939, _3#15940]</span><br></pre></td></tr></table></figure>

<p>这里可以看到几点变化：</p>
<ol>
<li>Filter被下推，直接作用于<code>LocalRelation</code>。 适用的规则为<code>PushDownPredicate</code></li>
<li><code>2 - 1</code> 被替换成了<code>1</code>。 适用的规则为<code>ConstantFolding</code></li>
<li><code>SubqueryAlia</code>节点被直接优化掉了</li>
<li><code>cast(1400 as double)</code>被换成了<code>1400.0</code></li>
</ol>
<h3 id="2-1-3-Write-rules-for-logical-plan"><a href="#2-1-3-Write-rules-for-logical-plan" class="headerlink" title="2.1.3 Write rules for logical plan"></a>2.1.3 Write rules for logical plan</h3><blockquote>
<p>Catalyst operates with logical plans and expressions, even attribute is an expression. Below are some examples how to convert one expression into another another using rules. Each logical plan is essentially a bunch of <code>QueryPlan[LogicalPlan]</code> instances and <code>Expression</code> expressions. Some examples of logical plans are <code>Project</code>, <code>Generate</code>, <code>Filter</code>, etc.</p>
</blockquote>
<p>翻译一下：</p>
<blockquote>
<p> Catalyst操作的对象是_logical plans_以及_expressions_， 即使是attribute也是一种expression。下边是一些使用规则(rule)将一个表达式转换成另一个的例子。每个logical plan本质是就是一组<code>QueryPlan[LogicalPlan]</code>实例和<code>Expression</code>表达式。logical plan的例子包括<code>Project</code>, <code>Generate</code>, <code>Filter</code>等。</p>
</blockquote>
<p>这里有一些东东不大明白：</p>
<ol>
<li><code>QueryPlan[LogicalPlan]</code>是个什么东东？</li>
<li><strong>plan</strong>这个概念和<strong>expression</strong>有啥区别？</li>
</ol>
<p>继续往下看</p>
<h4 id="2-1-3-1-expression的转换"><a href="#2-1-3-1-expression的转换" class="headerlink" title="2.1.3.1 expression的转换"></a>2.1.3.1 expression的转换</h4><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Simple expression transform</span></span><br><span class="line"><span class="keyword">val</span> add = <span class="type">Add</span>(<span class="type">Literal</span>(<span class="number">2</span>), <span class="type">Literal</span>(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> subtract = add transform &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Add</span>(left, right) =&gt; <span class="type">Subtract</span>(left, right)</span><br><span class="line">&#125;</span><br><span class="line">add: org.apache.spark.sql.catalyst.expressions.<span class="type">Add</span> = (<span class="number">2</span> + <span class="number">3</span>)</span><br><span class="line">subtract: org.apache.spark.sql.catalyst.expressions.<span class="type">Expression</span> = (<span class="number">2</span> - <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>Analyzer is built from rules, each rule is essentially one operation that takes logical plan and returns logical plan with very minimal change, hopefully better change. See example below:</p>
</blockquote>
<p>是说rule就是一个operator，输入和输出都是logical plan， 不过这俩logical plan会有些许不同，目的是进行一些优化。</p>
<p><code>transform</code>方法的定义为</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">transform</span></span>(rule: <span class="type">PartialFunction</span>[<span class="type">BaseType</span>, <span class="type">BaseType</span>]): <span class="type">BaseType</span> = &#123;</span><br><span class="line">  transformDown(rule)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里的</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="type">Add</span>(left, right) =&gt; <span class="type">Subtract</span>(left, right)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>就是一个rule。<code>add</code>和<code>subtract</code>就是两个<code>Expression</code>。这里通过一个自己实现的rule，将<code>Add</code>表达式转成了<code>Subtract</code>表达式。</p>
<h4 id="2-1-3-2-TreeNode"><a href="#2-1-3-2-TreeNode" class="headerlink" title="2.1.3.2 TreeNode"></a>2.1.3.2 TreeNode</h4><p><code>transform</code>是<code>Add</code>继承自<code>TreeNode</code>的方法。</p>
<p>这里<code>TreeNode</code>的类型参数有点绕。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">abstract class TreeNode[BaseType &lt;: TreeNode[BaseType]] extends Product &#123;</span><br><span class="line">&#x2F;&#x2F; scalastyle:on</span><br><span class="line">  self: BaseType &#x3D;&gt;</span><br></pre></td></tr></table></figure>

<p>在这里要注意两点</p>
<ol>
<li><p><code>TreeNode</code>是一个<strong>invariant</strong>  class，不是协变类，也不是逆变类。</p>
</li>
<li><p><code>TreeNode</code>要求其自身是一个<code>BaseType</code>。也就是说， <code>BaseType</code>实际上就是指它自己或它的子类。这样在定义方法的时候就可以用到这个限制。比如，<code>TreeNode</code>的foreach方法这么定义</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Runs the given function on this node and then recursively on [[children]].</span><br><span class="line"> * @param f the function to be applied to each node in the tree.</span><br><span class="line"> *&#x2F;</span><br><span class="line">def foreach(f: BaseType &#x3D;&gt; Unit): Unit &#x3D; &#123;</span><br><span class="line">  f(this)</span><br><span class="line">  children.foreach(_.foreach(f))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里之所以可以<code>f(this)</code>, 就是因为<code>self: BaseType =&gt;</code>这个自身类型限制。如果去掉自身类型的限制，那么就<code>f(this)</code>就不合语法了。</p>
</li>
</ol>
<p>实际上它的直接子类都这样类义的：</p>
<p><strong>Expression</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Expression</span> <span class="keyword">extends</span> <span class="title">TreeNode</span>[<span class="type">Expression</span>]</span></span><br></pre></td></tr></table></figure>

<p><strong>Block</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Block</span> <span class="keyword">extends</span> <span class="title">TreeNode</span>[<span class="type">Block</span>] <span class="keyword">with</span> <span class="title">JavaCode</span></span></span><br></pre></td></tr></table></figure>

<p><strong>QueryPlan</strong></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">QueryPlan</span>[<span class="type">PlanType</span> &lt;: <span class="type">QueryPlan</span>[<span class="type">PlanType</span>]] <span class="keyword">extends</span> <span class="title">TreeNode</span>[<span class="type">PlanType</span>] </span>&#123;</span><br><span class="line">  self: <span class="type">PlanType</span> =&gt;</span><br></pre></td></tr></table></figure>

<p>这样写的话，<code>Expression</code>继承的<code>TreeNode</code>的方法，如果参数类型是<code>BaseType</code>，那么就只能传进去<code>Expression</code>的子类，而不能传进去<code>Block</code>的子类。</p>
<p>这样是不可以的</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> plan3 = add transform &#123;</span><br><span class="line">    <span class="keyword">case</span> foo: <span class="type">LogicalPlan</span> =&gt; foo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>就会报错</p>
<blockquote>
<p>pattern type is incompatible with expected type;<br>found   : org.apache.spark.sql.catalyst.plans.logical.LogicalPlan<br>required: org.apache.spark.sql.catalyst.expressions.Expression<br>case foo: LogicalPlan =&gt; foo</p>
</blockquote>
<p>也就是说add接受的transform实际上的类型要求是<code>PartialFunction[Expression, Expression]</code> (这里要注意PartitalFunction的型变)。</p>
<p>这么搞，有利于递归调用rule的时候避免错误匹配，比如一个用于<code>Expression</code>的规则被误用到了一个<code>LogicalPlan</code>，就要出问题了。</p>
<h3 id="2-1-4-Existing-filter-optimizations"><a href="#2-1-4-Existing-filter-optimizations" class="headerlink" title="2.1.4 Existing filter optimizations"></a>2.1.4 Existing filter optimizations</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> logicalPlan = <span class="type">LocalRelation</span>(int(<span class="symbol">'a</span>), str(<span class="symbol">'b</span>)).</span><br><span class="line">  select(<span class="symbol">'a</span>).</span><br><span class="line">  where(<span class="type">GreaterThan</span>(<span class="type">Add</span>(<span class="symbol">'a</span>, <span class="type">Literal</span>(<span class="number">1</span>)), <span class="type">Literal</span>(<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> analyzedPlan = logicalPlan.analyze</span><br><span class="line"><span class="keyword">val</span> optimizedPlan = <span class="type">SimpleTestOptimizer</span>.execute(analyzedPlan)</span><br></pre></td></tr></table></figure>

<p>结果为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">logicalPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">&#39;Filter ((&#39;a + 1) &gt; 2)</span><br><span class="line">+- &#39;Project [&#39;a]</span><br><span class="line">   +- LocalRelation &lt;empty&gt;, [a#21651, b#21652]</span><br><span class="line"></span><br><span class="line">analyzedPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">Filter ((a#21651 + 1) &gt; 2)</span><br><span class="line">+- Project [a#21651]</span><br><span class="line">   +- LocalRelation &lt;empty&gt;, [a#21651, b#21652]</span><br><span class="line"></span><br><span class="line">optimizedPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">Project [a#21651]</span><br><span class="line">+- Filter (isnotnull(a#21651) &amp;&amp; ((a#21651 + 1) &gt; 2))</span><br><span class="line">   +- LocalRelation &lt;empty&gt;, [a#21651, b#21652]</span><br></pre></td></tr></table></figure>

<p>这里可以看到<code>((a#21651 + 1) &gt; 2))</code>并非最优的形式。所以，下面自己创建一个rule来解析这个表达式。</p>
<h3 id="2-1-5-Optimize-filter-folding"><a href="#2-1-5-Optimize-filter-folding" class="headerlink" title="2.1.5 Optimize filter folding"></a>2.1.5 Optimize filter folding</h3><p>创建一个<code>Rule</code>，叫做<code>SimpleFilterFolding</code>。代码为</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Let's call our rule SimpleFilterFolding</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleFilterFolding</span> <span class="keyword">extends</span> <span class="title">Rule</span>[<span class="type">LogicalPlan</span>] </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(plan: <span class="type">LogicalPlan</span>): <span class="type">LogicalPlan</span> = plan transform &#123;</span><br><span class="line">    <span class="comment">// We take logical plan and only apply our rule when we encounter filter with a simple `add` condition</span></span><br><span class="line">    <span class="keyword">case</span> filter @ <span class="type">Filter</span>(condition, _) =&gt; filter transformExpressionsUp &#123;</span><br><span class="line">      <span class="comment">// What we need to do is replacing our filter where `expr` is greater than right side - literal</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">GreaterThan</span>(<span class="type">Add</span>(expr, literal: <span class="type">Literal</span>), right) =&gt; </span><br><span class="line">        <span class="type">GreaterThan</span>(expr, <span class="type">Subtract</span>(right, literal))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后把这个rule注册到我们的optimizer中。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleOptimizer</span> <span class="keyword">extends</span> <span class="title">RuleExecutor</span>[<span class="type">LogicalPlan</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> batches = <span class="type">Batch</span>(<span class="string">"Filter folding"</span>, <span class="type">Once</span>, </span><br><span class="line">    <span class="type">SimpleFilterFolding</span>) :: <span class="type">Nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// We take analyzed plan and run through Optimizer object</span></span><br><span class="line"><span class="keyword">val</span> optimizedPlan = <span class="type">SimpleOptimizer</span>.execute(analyzedPlan)</span><br></pre></td></tr></table></figure>

<p>结果为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">defined module SimpleOptimizer</span><br><span class="line">optimizedPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">Filter (a#21651 &gt; (2 - 1))</span><br><span class="line">+- Project [a#21651]</span><br><span class="line">   +- LocalRelation &lt;empty&gt;, [a#21651, b#21652]</span><br></pre></td></tr></table></figure>

<p>这里<code>(2 - 1)</code>并没有被优化掉。但是已有rule可以做这件事，就是叫做<code>ConstantFolding</code>的rule，现在把它跟我们的rule一起使用。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleOptimizer</span> <span class="keyword">extends</span> <span class="title">RuleExecutor</span>[<span class="type">LogicalPlan</span>] </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> batches = <span class="type">Batch</span>(<span class="string">"Filter folding"</span>, <span class="type">Once</span>, </span><br><span class="line">    <span class="type">SimpleFilterFolding</span>, <span class="type">ConstantFolding</span>) :: <span class="type">Nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// We take analyzed plan and run through Optimizer object</span></span><br><span class="line"><span class="keyword">val</span> optimizedPlan = <span class="type">SimpleOptimizer</span>.execute(analyzedPlan)</span><br></pre></td></tr></table></figure>

<p>这样结果就对了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">defined module SimpleOptimizer</span><br><span class="line">optimizedPlan: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan &#x3D; </span><br><span class="line">Filter (a#21651 &gt; 1)</span><br><span class="line">+- Project [a#21651]</span><br><span class="line">   +- LocalRelation &lt;empty&gt;, [a#21651, b#21652]</span><br></pre></td></tr></table></figure>



<p>Spark 3.0的在filter pushdown方面有了进步，这个下个blog再研究。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul>
<li><a href="https://docs.datafabric.hpe.com/61/Spark/ProjectionFilterPushdownDataFramesDatasets.html">Projection and Filter Pushdown with Apache Spark DataFrames and Datasets</a></li>
<li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/4201913720573284/4413065072037724/latest.html">Filter pushdown</a></li>
</ul>
</div></article></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/birds.jpg" alt="iBuddha"></figure><p class="title is-size-4 is-block line-height-inherit">iBuddha</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">4</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ibuddha" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ibuddha"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Rust/"><span class="level-start"><span class="level-item">Rust</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/hadoop/"><span class="level-start"><span class="level-item">hadoop</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/spark/"><span class="level-start"><span class="level-item">spark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-16T13:45:54.000Z">2020-08-16</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/16/pushdown/">spark里的filter和projection pushdown</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/spark/">spark</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-11T14:44:54.000Z">2020-07-11</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/11/hadoop-empty-configuration/">如何得到一个空的Hadoop Configuration</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/hadoop/">hadoop</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2018-06-06T16:00:00.000Z">2018-06-07</time></p><p class="title is-6"><a class="link-muted" href="/2018/06/07/mio_poll/">mio::poll文档 —— 翻译和注解</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Rust/">Rust</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2018-05-16T16:00:00.000Z">2018-05-17</time></p><p class="title is-6"><a class="link-muted" href="/2018/05/17/Rust_a_complex_example/">关于reborrow的一个复杂的例子</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Rust/">Rust</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">八月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">七月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/06/"><span class="level-start"><span class="level-item">六月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2018/05/"><span class="level-start"><span class="level-item">五月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Network/"><span class="tag">Network</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Rust/"><span class="tag">Rust</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hadoop/"><span class="tag">hadoop</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/lotus.png" alt="iBuddha" height="28"></a><p class="size-small"><span>&copy; 2020 xing</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://ibuddha.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>